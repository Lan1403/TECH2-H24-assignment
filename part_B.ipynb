{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TECH 2 mandatory assignment - Part B\n",
    "\n",
    "Write your solution for Part B in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 1 (100 numbers): [0.6823518632481435, 0.053821018802222675, 0.22035987277261138, 0.1843718106986697, 0.17590590108503035] ... Length: 100\n",
      "Column 2 (1,000 numbers): [0.6823518632481435, 0.053821018802222675, 0.22035987277261138, 0.1843718106986697, 0.17590590108503035] ... Length: 1000\n",
      "Column 3 (10,000 numbers): [0.6823518632481435, 0.053821018802222675, 0.22035987277261138, 0.1843718106986697, 0.17590590108503035] ... Length: 10000\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from math import sqrt\n",
    "from part_A import std_loops, std_builtin, std_numpy\n",
    "import numpy as np\n",
    "\n",
    "def import_data(filename):\n",
    "    col1, col2, col3 = [], [], []\n",
    "    \n",
    "    with open(filename, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        for row in reader:\n",
    "                try:\n",
    "                    if row[0] != '' :\n",
    "                        col1.append(float(row[0]))\n",
    "                    if row[1] != '':\n",
    "                        col2.append(float(row[1]))\n",
    "                    if row[2] != '':\n",
    "                        col3.append(float(row[2]))\n",
    "                except ValueError:\n",
    "                    print(f\"Skipping invalid row: {row}\")\n",
    "    \n",
    "    return col1, col2, col3\n",
    "\n",
    "col1, col2, col3 = import_data('data.csv')\n",
    "\n",
    "print(f\"Column 1 (100 numbers): {col1[:5]} ... Length: {len(col1)}\")\n",
    "print(f\"Column 2 (1,000 numbers): {col2[:5]} ... Length: {len(col2)}\")\n",
    "print(f\"Column 3 (10,000 numbers): {col3[:5]} ... Length: {len(col3)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timing loops function\n",
      "6.59 μs ± 135 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n",
      "61.8 μs ± 426 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n",
      "656 μs ± 36.3 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n",
      "\n",
      "Timing built-in function\n",
      "5.4 μs ± 127 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n",
      "53.8 μs ± 589 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n",
      "531 μs ± 6.82 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n",
      "\n",
      "Timing NumPy function\n",
      "9.99 μs ± 191 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n",
      "33.3 μs ± 1.02 μs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n",
      "296 μs ± 5.32 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# Timing loops function for each column\n",
    "print(\"Timing loops function\")\n",
    "%timeit std_loops(col1)  #100 numbers\n",
    "%timeit std_loops(col2)  #1,000 numbers\n",
    "%timeit std_loops(col3)  #10,000 numbers\n",
    "\n",
    "# Timing built-in function for each column\n",
    "print(\"\\nTiming built-in function\")\n",
    "%timeit std_builtin(col1)  #100 numbers\n",
    "%timeit std_builtin(col2)  #1,000 numbers\n",
    "%timeit std_builtin(col3)  #10,000 numbers\n",
    "\n",
    "# Timing NumPy function for each column\n",
    "print(\"\\nTiming NumPy function\")\n",
    "%timeit std_numpy(col1)  #100 numbers\n",
    "%timeit std_numpy(col2)  #1,000 numbers\n",
    "%timeit std_numpy(col3)  #10,000 numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the small amount of datasets, built-in seems like the fastest way to compute standard deviation. However, when the amount of datassets increase, Numpy function take the shortest time to compute standard deviation. So for the larger datasets, it is better to use NumPy function.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TECH2-assignment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
