{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TECH 2 mandatory assignment - Part B\n",
    "\n",
    "Write your solution for Part B in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 1 (100 numbers): [0.6823518632481435, 0.053821018802222675, 0.22035987277261138, 0.1843718106986697, 0.17590590108503035] ... Length: 100\n",
      "Column 2 (1,000 numbers): [0.6823518632481435, 0.053821018802222675, 0.22035987277261138, 0.1843718106986697, 0.17590590108503035] ... Length: 1000\n",
      "Column 3 (10,000 numbers): [0.6823518632481435, 0.053821018802222675, 0.22035987277261138, 0.1843718106986697, 0.17590590108503035] ... Length: 10000\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from math import sqrt\n",
    "from part_A import std_loops, std_builtin, std_numpy\n",
    "import numpy as np\n",
    "\n",
    "def import_data(filename):\n",
    "    col1, col2, col3 = [], [], []\n",
    "    \n",
    "    with open(filename, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        for row in reader:\n",
    "                try:\n",
    "                    if row[0] != '' :\n",
    "                        col1.append(float(row[0]))\n",
    "                    if row[1] != '':\n",
    "                        col2.append(float(row[1]))\n",
    "                    if row[2] != '':\n",
    "                        col3.append(float(row[2]))\n",
    "                except ValueError:\n",
    "                    print(f\"Skipping invalid row: {row}\")\n",
    "    \n",
    "    return col1, col2, col3\n",
    "\n",
    "col1, col2, col3 = import_data('data.csv')\n",
    "\n",
    "print(f\"Column 1 (100 numbers): {col1[:5]} ... Length: {len(col1)}\")\n",
    "print(f\"Column 2 (1,000 numbers): {col2[:5]} ... Length: {len(col2)}\")\n",
    "print(f\"Column 3 (10,000 numbers): {col3[:5]} ... Length: {len(col3)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timing std_loops()\n",
      "6.46 μs ± 67.8 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n",
      "62.1 μs ± 650 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n",
      "607 μs ± 2.88 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n",
      "\n",
      "Timing std_builtin()\n",
      "5.37 μs ± 94.5 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n",
      "54 μs ± 1.11 μs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n",
      "527 μs ± 4.54 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n",
      "\n",
      "Timing std_numpy()\n",
      "9.95 μs ± 67.9 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n",
      "33.7 μs ± 870 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n",
      "268 μs ± 9.47 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# Timing std_loops for each column\n",
    "print(\"Timing std_loops()\")\n",
    "%timeit std_loops(col1)  #100 numbers\n",
    "%timeit std_loops(col2)  #1,000 numbers\n",
    "%timeit std_loops(col3)  #10,000 numbers\n",
    "\n",
    "# Timing std_builtin for each column\n",
    "print(\"\\nTiming std_builtin()\")\n",
    "%timeit std_builtin(col1)  #100 numbers\n",
    "%timeit std_builtin(col2)  #1,000 numbers\n",
    "%timeit std_builtin(col3)  #10,000 numbers\n",
    "\n",
    "# Timing std_numpy for each column\n",
    "print(\"\\nTiming std_numpy()\")\n",
    "%timeit std_numpy(col1)  #100 numbers\n",
    "%timeit std_numpy(col2)  #1,000 numbers\n",
    "%timeit std_numpy(col3)  #10,000 numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the small amount of datasets, built-in seems like the fastest way to compute standard deviation. However, when the amount of datassets increase, Numpy function take the shortest time to compute standard deviation. So for the larger datasets, it is better to use NumPy function.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TECH2-assignment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
